# Поддерживающие системы Neira

## Навигация
- [Обзор Нейры](README.md)
- [Узлы действий](action-nodes.md)
- [Узлы анализа](analysis-nodes.md)
- [Узлы памяти](memory-nodes.md)
- [Архитектура анализа](analysis-architecture.md)
- [Поддерживающие системы](support-systems.md)
- [Личность Нейры](personality.md)
- [Шаблон узла](node-template.md)
- [Политика источников](source-policy.md)

## Оглавление
- [InteractionHub](#interactionhub)
- [TaskScheduler](#taskscheduler)
- [Feedback Aggregator](#feedback-aggregator)
- [Memory Nodes](#memory-nodes)
- [Рабочая память](#рабочая-память)
- [Модуль эмоций](#модуль-эмоций)
- [Диалоговая логика](#диалоговая-логика)
- [Модуль личности](#модуль-личности)
- [Игровой модуль](#игровой-модуль)
- [Скептический модуль](#скептический-модуль)
- [CLI для управления версиями узлов](#cli-для-управления-версиями-узлов)
- [Уведомления о прогрессе](#уведомления-о-прогрессе)


## InteractionHub
Единый оркестратор, через который проходят все запросы пользователя. Он регистрирует события, проверяет права доступа и направляет обращения к нужным узлам. InteractionHub агрегирует ответы ActionNode и MemoryNode, связывая их с исходным контекстом и формируя итоговый результат.

```rust
struct InteractionHub {
    sessions: HashMap<SessionId, Context>,
    log: EventLog,
}
```

### Последовательность вызовов
1. `receive(request)` — фиксирует обращение и создаёт `request_id`.
2. `authorize(context)` — проверяет права пользователя и окружение.
3. `dispatch(request)` — направляет запрос в соответствующие `ActionNode` и `MemoryNode`.
4. Узлы возвращают промежуточные ответы и события.
5. `aggregate(results)` — объединяет ответы узлов с исходным контекстом.
6. `respond(aggregate)` — формирует итоговый ответ и записывает его в журнал.

### Формат ответа
InteractionHub возвращает объект с итоговым результатом и идентификатором запроса:

```json
{
  "request_id": "<uuid>",
  "input": "<исходный текст>",
  "output": "<финальный ответ>",
  "reasoning_snippet": "<краткое объяснение шага>",
  "errors": null
}
```

#### Пример

```json
{
  "request_id": "f65c3b9a-9e2a-4c39-8e27-1f523b9a8b5b",
  "input": "Где находится Эйфелева башня?",
  "output": "Эйфелева башня расположена в Париже, Франция.",
  "reasoning_snippet": "Проверяю факты о достопримечательностях"
}
```

## TaskScheduler
`TaskScheduler` распределяет задачи по очередям `fast`, `standard` и `long` в зависимости от оценки длительности. AnalysisNode передаёт задачу в соответствующий канал, а Scheduler отвечает за параллелизм и контроль квот, учитывая параметры `priority`, `max_iterations` и `time_slice_ms` каждого узла (см. [«Планировщик и лимиты итераций»](README.md#планировщик-и-лимиты-итераций)). При недоступности основной машины планировщик автоматически переключает задачи на резервные узлы.

Помимо RAM и VRAM, планировщик учитывает отдельный бюджет NVRAM/PMEM через параметр `pmem_limit_mb`.

```toml
[scheduler]
fast = 60_000          # 1 минута
standard = 1_800_000   # 30 минут
long = 28_800_000      # 8 часов
global_time_budget = 86_400_000 # 24 часа на весь запрос
cancel_token_poll_ms = 500      # проверка отмены раз в 0.5 с
checkpoint_interval_ms = 1_000  # сохранение состояния раз в 1 с
```

### Операционные лимиты планировщика

Планировщик задаёт собственные операционные бюджеты использования ресурсов. Они используются для распределения задач и не отражают фактических ограничений железа (см. [«Минимальное окружение»](README.md#минимальное-окружение)).

Этот бюджет намеренно ниже доступных физических ресурсов и служит внутренним ограничением. Например, на машине с 4 CPU и 8 ГБ RAM планировщик по умолчанию резервирует 2 CPU и 4 ГБ, оставляя остальное хосту.

| Ресурс | Операционный бюджет |
|--------|---------------------|
| CPU    | 2 ядра |
| RAM    | 4 ГБ |
| GPU    | 0 |

GPU‑бюджет по умолчанию равен нулю, но для задач, вынесенных на ускоритель, его можно увеличить:

```toml
[scheduler]
gpu_cores = N  # пример: выделить N GPU ядер
```

Для распределённых сценариев можно задать предел пропускной способности сети:

```toml
[scheduler]
net_bandwidth_mb = 125  # ~1 Гбит/с на запрос
```

#### Лимиты по типам памяти

| Тип памяти | Операционный бюджет |
|------------|---------------------|
| ОЗУ        | 4 ГБ                |
| VRAM       | 0 ГБ                |
| PMEM       | 0 ГБ                |
| SSD/HDD    | 50 ГБ               |

Узлы, которым необходим конкретный ускоритель (GPU, TPU, FPGA), добавляют в метаданные поле `required_accelerator`. Это позволяет `TaskScheduler` направлять задачи на подходящие устройства:

```json
{
  "required_accelerator": "gpu",
  "resources": { "gpu": 1 }
}
```

При прямом доступе к ускорителям в виртуализированных средах включайте IOMMU и используйте GPU‑passthrough, чтобы узел видел только выделенное устройство и не мог обращаться к памяти хоста.

Бюджеты намеренно устанавливаются ниже физических пределов машины, оставляя резерв под операционную систему и фоновые сервисы. Значения берутся из конфигурации планировщика и при необходимости могут масштабироваться.

Пример конфигурации с указанием бюджетов по типам памяти:

```toml
[scheduler.memory]
ram_limit_mb = 4096
vram_limit_mb = 0
pmem_limit_mb = 0
ssd_space_mb = 51200
```

В качестве базового окружения используется [стандартная конфигурация](README.md#стандартная-конфигурация): 8-ядерный CPU ≥2.5 ГГц, 32 ГБ RAM, SSD 512 ГБ и опциональная CUDA‑совместимая GPU ≥8 ГБ VRAM. Она обеспечивает баланс удобства разработки и стоимости и применяется по умолчанию, если проект не предъявляет особых требований.

- Приоритет задач определяется методом `get_priority()` узлов памяти, который учитывает `QualityMetrics` и `UsageStats`.
- Scheduler периодически пересчитывает приоритеты на основе агрегированной статистики и передаёт обновлённые значения связанным AnalysisNode.

### global_time_budget, cancel_token и checkpointing

Планировщик отслеживает суммарный `global_time_budget` и при превышении лимита
сигнализирует об отмене через `cancel_token`. Узлы обязаны регулярно проверять
этот токен и при остановке сохранять прогресс в чекпоинты. Контрольные точки
(`checkpointing`) позволяют возобновить выполнение задачи после перезапуска или
повторного планирования.

## Feedback Aggregator
Агрегатор собирает сигналы от пользователей и автотестов. Он ведёт единый поток обратной связи, влияющий на приоритеты обслуживания узлов памяти.

```rust
struct FeedbackEntry {
    node_id: NodeId,
    source: FeedbackSource,
    metric: String,
    score: f32,
    timestamp: DateTime<Utc>,
}
```

Поток работы:

1. событие фиксируется как `FeedbackEntry`;
2. агрегатор обновляет `QualityMetrics` и `UsageStats` соответствующего узла памяти;
3. планировщик вызывает `update_priority()` узлов памяти на основании обновлённой статистики.

Подробнее см. разделы [analysis-nodes](analysis-nodes.md) и [memory-nodes](memory-nodes.md).

## Memory Nodes
Узлы памяти могут размещаться на разных уровнях хранения и вычислений, что позволяет балансировать скорость и объём данных:

- **RAM** — краткоживущий контекст, результаты последних шагов и лёгкие CPU-вычисления.
- **VRAM** — тензоры и модели для массовых параллельных операций на GPU.
- **PMEM** — энергонезависимый слой с задержкой ниже SSD; подходит для кэша моделей и журнальных файлов.
- **Выделенные узлы памяти** — долговременные базы на SSD/HDD или сетевые кластеры, где возможна асинхронная обработка больших массивов данных.

Критерии выбора носителя:

- частота доступа к данным;
- объём данных;
- требуемая скорость.

При переносе данных между уровнями следует учитывать политику кэширования, резервное копирование, а также сетевые ограничения:
пропускную способность и задержки, влияющие на скорость обмена между узлами.

### Пример конфигурации
```toml
[memory_nodes.vector_cache]
storage = "gpu"

[memory_nodes.session_cache]
storage = "ram"

[memory_nodes.model_cache]
storage = "pmem" # кэш моделей и журналы с низкой задержкой
```

## Система пакетов
Пакеты позволяют расширять Нейру новыми возможностями без изменения ядра. Каждый пакет
содержит метаданные и исходный код модуля.

```text
draw/
├── package.toml
├── README.md
└── src/
    └── lib.rs
```

В файле `package.toml` описываются имя, версия и точка входа:

```toml
name = "draw"
version = "0.1.0"
entry = "src/lib.rs"
```

### package.manifest
Файл `package.manifest` определяет права пакета. В секции `permissions`
указываются четыре базовых типа разрешений:

- `fs` — доступ к файловой системе;
- `net` — разрешённые сетевые адреса;
- `cpu` — допустимая доля времени процессора;
- `mem` — лимит оперативной памяти.

```toml
# package.manifest
[permissions]
fs = ["read:/data", "write:/tmp"]
net = ["https://api.example.com"]
cpu = 0.5
mem = "128MB"
```
Если пакет должен выполняться только в изолированной среде, добавьте секцию `[runtime]`:

```toml
# package.manifest
[runtime]
isolated = true

[permissions]
fs = ["read:/data", "write:/tmp"]
net = ["https://api.example.com"]
cpu = 0.5
mem = "128MB"
```
Пример такого файла включён в репозиторий: [`examples/package-isolated.manifest`](../../examples/package-isolated.manifest).

### Управление пакетами
Пакеты устанавливаются и обновляются через CLI:

```bash
neira pkg install draw   # установка
neira pkg update draw    # обновление
neira pkg remove draw    # удаление
```

### Проверка подписи и откат
Перед запуском пакета рекомендуется проверить его подпись:

```bash
neira pkg verify draw    # проверка подписи
```

При необходимости можно откатить пакет к предыдущей версии:

```bash
neira pkg rollback draw --version 0.1.0
```

### Минимальный пример
Простейший пакет может предоставлять модуль рисования:

```rust
// src/lib.rs
pub fn init() {
    canvas::line(Point::new(0, 0), Point::new(10, 10));
}
```

## Рабочая память
Временное хранилище актуального контекста. Содержит последние сообщения, переменные запроса и результаты промежуточных вычислений. Записи автоматически вытесняются по таймеру или при переполнении лимита.

```rust
struct WorkingMemory {
    messages: Vec<Message>,
    variables: HashMap<String, Value>,
    ttl: Duration,
}
```

### Методы доступа
- `store(context)` — добавляет сообщения и переменные в память, обновляя таймер `ttl`;
- `retrieve(key)` — возвращает сохранённое значение или сообщение по ключу;
- `evict(expired)` — удаляет записи, у которых `ttl` истёк или превышен лимит памяти.

### Пример состояния
```json
{
  "messages": [
    { "role": "user", "content": "Привет" },
    { "role": "assistant", "content": "Чем могу помочь?" }
  ],
  "variables": { "topic": "travel", "step": 2 },
  "ttl": 600000
}
```

## Модуль эмоций
Следит за тоном диалога и внутренним состоянием системы. Положительные сигналы усиливают инициативность, негативные — вызывают осторожность и запрос на уточнение. Эмоции не влияют на логику вывода, но помогают выбирать стиль ответа.

## Диалоговая логика
Определяет намерение пользователя и выбирает стиль ответа. Также решает, когда активировать образ Нейры, а когда переключиться на сухой режим. Детали по доступным логам и объяснениям в разных режимах см. в разделе [«Логи и объяснения по режимам»](personality.md#логи-и-объяснения-по-режимам).

## Модуль личности
Хранит характеристики персонажа и набор устойчивых фраз. Может быть временно отключён для экономии ресурсов или по запросу пользователя.

## Игровой модуль
Использует игровые сценарии как способ обучения и мотивации. Во время игр анализируются сюжет, актёрская работа и нестандартные ситуации, формируя новые узлы анализа.

## Скептический модуль
Добавляет уточняющие вопросы и проверку фактов. В сухом режиме может отключаться для ускорения работы.

## CLI для управления версиями узлов
Команды CLI взаимодействуют с `VersionManager` и `NodeRegistry`:

```bash
neira promote <node_id> --version 2.0.0   # сделать версию активной
neira rollback <node_id> --version 1.5.0  # вернуться к стабильной
neira archive <node_id> --version 1.4.0   # удалить из реестра
```

Эти операции обновляют реестр и фиксируются в журнале `NodeVersion`.

## Уведомления о прогрессе
Для задач класса `standard` и `long` InteractionHub отправляет промежуточные сообщения о ходе выполнения. Scheduler выдаёт процент готовности, который отображается пользователю. После завершения задача помечается в журнале и из рабочей памяти удаляются временные записи.

### Формат прогресса
Каждое уведомление содержит краткую информацию о текущем шаге:

```json
{
  "status": "running",
  "step": "fetch_memory",
  "reasoning_snippet": "извлекаю факты о Париже"
}
```

Поле `status` показывает состояние задачи, `step` описывает текущий этап, а `reasoning_snippet` содержит короткий фрагмент цепочки рассуждений.

## Схемы

JSON‑схемы расположены в каталоге [../../schemas](../../schemas). При несовместимых изменениях повышайте версию: `1.0.0` → `1.1.0`.
